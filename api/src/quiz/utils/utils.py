import os
from langchain.chat_models import ChatOpenAI
from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler
from langchain_core.output_parsers import StrOutputParser
from langchain_core.prompts import load_prompt
from src.quiz.utils.fewshot import sample_fewshot
import json
import random
import openai

# random content, type ì„¸íŠ¸ ë§Œë“¤ê¸°

async def make_set(quiz_content,quiz_type,number):
    set_type = [(q_content,q_type) for q_content in quiz_content for q_type in quiz_type]
    q_set = []
    if len(set_type)>= number:
        # ê° quiz_typeì„ ìµœëŒ€í•œ ê³¨ê³ ë£¨ ì„ íƒí•˜ê¸° ìœ„í•œ ì•Œê³ ë¦¬ì¦˜
        quiz_type_cycle = iter(random.sample(quiz_type, len(quiz_type)))  # quiz_typeì„ ì„ì–´ì„œ ìˆœí™˜
        while len(q_set) < number:
            q_content = random.choice(quiz_content)  # ëœë¤í•˜ê²Œ quiz_content ì„ íƒ
            q_type = next(quiz_type_cycle, None)  # quiz_typeì„ ìˆœì°¨ì ìœ¼ë¡œ ì„ íƒ
            
            if q_type is None:  # quiz_typeì„ ëª¨ë‘ ìˆœí™˜í–ˆìœ¼ë©´ ë‹¤ì‹œ ì„ì–´ì„œ ìˆœí™˜
                quiz_type_cycle = iter(random.sample(quiz_type, len(quiz_type)))
                q_type = next(quiz_type_cycle)
            
            # ì¤‘ë³µë˜ì§€ ì•Šê²Œ ì¡°í•©ì„ ì¶”ê°€
            if (q_content, q_type) not in q_set:
                q_set.append((q_content, q_type))
    else:
        for _ in range(number//len(set_type)):
            q_set += set_type
        q_set += random.sample(set_type,k=number%len(set_type))
    random.shuffle(q_set)
    return q_set

# async def quiz_format(text):
#     start = text.find('[')  # '['ë¡œ ì‹œì‘í•˜ëŠ” ë¶€ë¶„ì„ ì°¾ìŒ
#     end = text.rfind(']')   # ']'ë¡œ ëë‚˜ëŠ” ë¶€ë¶„ì„ ì°¾ìŒ
#     if start != -1 and end != -1:
#         json_data = text[start:end+1]  # JSON ë¶€ë¶„ë§Œ ì¶”ì¶œ
#         try:
#             parsed_data = json.loads(json_data)
        
#         except json.JSONDecodeError as e:
#             print("Failed to parse JSON:", e)
#             return None
#     else:
#         print("No valid JSON found in the result.")
#         return None

#     quiz = "ğŸš€ **Quiz**\n\n"
#     answer = "ğŸš€ **Answer**\n\n"
#     explain = "ğŸš€ **Explain**\n\n"
#     sentence = "ğŸš€ **Sentence**\n\n"
#     dialog = "ğŸš€ **Dialog**\n\n"

#     for idx, data in enumerate(parsed_data,start=1):
#         quiz += f"ğŸ”† Quiz {idx}. " + data["quiz"] + "\n\n"
#         if data["type"] !="fill_in_the_blank":
#             for choice in data["choice"]:
#                 quiz += choice + "\n\n"
#         answer += f"ğŸ”† Quiz {idx}. " + data["answer"]  + "\n\n"
#         explain += f"ğŸ”† Quiz {idx}. " + data["explain"] + "\n\n"
#         sentence += f"ğŸ”† Quiz {idx}. " + "\n\n"
#         for i, sen in enumerate(data["sentence"],start=1):
#             sentence += f"Example {i}. "  + sen + "\n\n"
#         dialog += f"ğŸ”† Quiz {idx}. " +"\n\n"
#         for i, dia in enumerate(data["dialog"],start=1):
#             dialog += dia + "\n\n"
#     # output = quiz + answer + explain + sentence + dialog
#     # print(output)
#     # return output
#     output_quiz = quiz 
#     output_answer = answer + explain + sentence + dialog
#     output = [output_quiz, output_answer]
#     return output

async def quiz_format(text):
    start = text.find('[')  # '['ë¡œ ì‹œì‘í•˜ëŠ” ë¶€ë¶„ì„ ì°¾ìŒ
    end = text.rfind(']')   # ']'ë¡œ ëë‚˜ëŠ” ë¶€ë¶„ì„ ì°¾ìŒ
    if start != -1 and end != -1:
        json_data = text[start:end+1]  # JSON ë¶€ë¶„ë§Œ ì¶”ì¶œ
        try:
            parsed_data = json.loads(json_data)
        
        except json.JSONDecodeError as e:
            print("Failed to parse JSON:", e)
            return None
    else:
        print("No valid JSON found in the result.")
        return None

    quiz = "ğŸš€ **Quiz**\n\n"
    answer_list = []

    for idx, data in enumerate(parsed_data,start=1):
        quiz += f"ğŸ”† Quiz {idx}. " + data["quiz"] + "\n\n"
        if data["type"] !="fill_in_the_blank":
            for choice in data["choice"]:
                quiz += choice + "\n\n"

        text = f"ğŸš€ **Quiz {idx}**\n\n"
        text += "ğŸ”† **Answer:** " + data["answer"] + "\n\n"
        text += "ğŸ”† **Explain:** " + data["explain"] + "\n\n"
        text += "ğŸ”† **Sentence:** " + "\n\n"
        for i, sen in enumerate(data["sentence"],start=1):
            text += f"Example {i}. "  + sen + "\n\n"
        text += "ğŸ”† **Dialog:** " + "\n\n"
        for i, dia in enumerate(data["dialog"],start=1):
            text += dia + "\n\n"
        answer_list.append(text)
    output_quiz = quiz
    output_answer = answer_list
    output = [output_quiz, output_answer]

    return output
    
# async def make_set(quiz_content,quiz_type,number):
#     set_type = [(q_content,q_type) for q_content in quiz_content for q_type in quiz_type]
#     q_set = []
#     if len(set_type)>= number:
#         q_set = random.sample(set_type,k=number)
#     else:
#         for _ in range(number//len(set_type)):
#             q_set += set_type
#         q_set += random.sample(set_type,k=number%len(set_type))
#     random.shuffle(q_set)
#     return q_set

# batch í€´ì¦ˆ ìƒì„±

async def batch_generate_gpt4o_quiz(
        openai_api_key,
        document,
        quiz_content,
        quiz_type,
        number
):

    llm = ChatOpenAI(model_name = "gpt-4o",streaming=True, callbacks=[StreamingStdOutCallbackHandler()],
                    temperature = 0.56,
                    openai_api_key= openai_api_key)
    #prompt = load_prompt(os.path.join('/app/src/quiz/utils/prompt', 'quiz_generator_pythonic.yaml'))
    prompt = load_prompt(os.path.join('/app/src/quiz/utils/prompt', 'quiz_generator_json.yaml'))
    topic = document.split('\n')[0]
    reference = '\n'.join(document.split('\n')[1:])
    q_set= await make_set(quiz_content,quiz_type,number)
    print(q_set)
    #input_data = {"topic": topic,"reference": reference,"quiz_content":quiz_content,"quiz_type":quiz_type,"number":number,"set":q_set}
    input_data = {"topic": topic,"reference": reference,"number":number,"set":q_set}

    chain = (
        prompt
        | llm
        | StrOutputParser()
    )

    #results = chain.invoke(input_data).replace("A:", "\n    A:").replace("B:","\n    B:").replace("â‘ ","\n    â‘ ").replace("â‘¡","    â‘¡").replace("â‘¢","    â‘¢").replace("â‘£","    â‘£")
    try:
        response = chain.invoke(input_data)
        results = await quiz_format(response)
        return results
    except openai.NotFoundError:
        return ["í† í°ì´ ë¶€ì¡±í•©ë‹ˆë‹¤",["í† í°ì´ ë¶€ì¡±í•©ë‹ˆë‹¤"]]
        
    except Exception as e:
        return ["ê¸°íƒ€ ì—ëŸ¬ ë°œìƒ",["ê¸°íƒ€ ì—ëŸ¬ ë°œìƒ"]]


# async def batch_generate_gpt4o_quiz(
#         openai_api_key,
#         document,
#         quiz_content,
#         quiz_type,
#         number
# ):

#     llm = ChatOpenAI(model_name = "gpt-4o", streaming=True, callbacks=[StreamingStdOutCallbackHandler()],
#                     temperature = 0,
#                     openai_api_key= openai_api_key)
#     #prompt = load_prompt(os.path.join('/app/src/quiz/utils/prompt', 'quiz_generator_pythonic.yaml'))
#     prompt = load_prompt(os.path.join('/app/src/quiz/utils/prompt', 'quiz_generator_pythonic_for_develop.yaml'))
#     topic = document.split('\n')[0]
#     reference = '\n'.join(document.split('\n')[1:])
#     q_set= await make_set(quiz_content,quiz_type,number)
#     input_data = {"topic": topic,"reference": reference,"quiz_content":quiz_content,"quiz_type":quiz_type,"number":number,"set":q_set}

#     chain = (
#         prompt
#         | llm
#         | StrOutputParser()
#     )

#     #results = chain.invoke(input_data).replace("A:", "\n    A:").replace("B:","\n    B:").replace("â‘ ","\n    â‘ ").replace("â‘¡","    â‘¡").replace("â‘¢","    â‘¢").replace("â‘£","    â‘£")
#     results = chain.invoke(input_data)
#     return results

# stream í€´ì¦ˆ ìƒì„±
# async def stream_generate_gpt4o_quiz(
#         openai_api_key,
#         document,
#         quiz_content,
#         quiz_type,
#         number
# ):

#     llm = ChatOpenAI(model_name = "gpt-4o", streaming=True, callbacks=[StreamingStdOutCallbackHandler()],
#                     temperature = 0,
#                     openai_api_key= openai_api_key)
#     #prompt = load_prompt(os.path.join('/app/src/quiz/utils/prompt', 'quiz_generator_pythonic.yaml'))
#     prompt = load_prompt(os.path.join('/app/src/quiz/utils/prompt', 'quiz_generator_pythonic_for_develop.yaml'))
#     topic = document.split('\n')[0]
#     reference = '\n'.join(document.split('\n')[1:])
#     q_set= await make_set(quiz_content,quiz_type,number)
#     input_data = {"topic": topic,"reference": reference,"quiz_content":quiz_content,"quiz_type":quiz_type,"number":number,"set":q_set}

#     chain = (
#         prompt
#         | llm
#         | StrOutputParser()
#     )

#     async def generate():
#         buffer = ""
#         async for chunk in chain.astream(input_data):
#             buffer += chunk
#             lines = buffer.split('\n')
            
#             # Process all complete lines
#             for line in lines[:-1]:
#                 #line = line.replace("ğŸ”†", "\n  ğŸ”†").replace("A:", "\n    A:").replace("B:","\n    B:").replace("â‘ ","\n    â‘ ").replace("â‘¡","    â‘¡").replace("â‘¢","    â‘¢").replace("â‘£","    â‘£")
#                 yield f"data: {json.dumps({'text': line})}\n\n"
            
#             # Keep the last (possibly incomplete) line in the buffer
#             buffer = lines[-1]

#         # Yield any remaining content in the buffer
#         if buffer:
#             #buffer = buffer.replace("ğŸ”†", "\n  ğŸ”†").replace("A:", "\n    A:").replace("B:","\n    B:").replace("â‘ ","\n    â‘ ").replace("â‘¡","    â‘¡").replace("â‘¢","    â‘¢").replace("â‘£","    â‘£")
#             yield f"data: {json.dumps({'text': buffer})}\n\n"
#     return generate

# batch ë²ˆì—­
async def batch_translate_gpt4o_quiz(
        openai_api_key,
        quiz,
        answer,
        language
):
    llm = ChatOpenAI(model_name = "gpt-4o", streaming=True, callbacks=[StreamingStdOutCallbackHandler()],
                    temperature = 0,
                    openai_api_key= openai_api_key)
    prompt = load_prompt(os.path.join('/app/src/quiz/utils/prompt', 'quiz_translator.yaml'))
    input_data = {"quiz": quiz,"answer":answer,"language":language}
    chain = (
        prompt
        | llm
        | StrOutputParser()
    )
    try:
        results=chain.invoke(input_data)
        return results

    except openai.NotFoundError:
        return "í† í°ì´ ë¶€ì¡±í•©ë‹ˆë‹¤"
        
    except Exception as e:
        return "ê¸°íƒ€ ì—ëŸ¬ ë°œìƒ"    


# stream ë²ˆì—­
async def stream_translate_gpt4o_quiz(
        openai_api_key,
        quiz,
        answer,
        language
):
    llm = ChatOpenAI(model_name = "gpt-4o", streaming=True, callbacks=[StreamingStdOutCallbackHandler()],
                    temperature = 0,
                    openai_api_key= openai_api_key)
    prompt = load_prompt(os.path.join('/app/src/quiz/utils/prompt', 'quiz_translator.yaml'))
    input_data = {"quiz": quiz,"answer":answer,"language":language}
    chain = (
        prompt
        | llm
        | StrOutputParser()
    )
    
    async def generate():
        try:
            buffer=""
            async for chunk in chain.astream(input_data):
                buffer +=chunk
                lines = buffer.split("\n")

                for line in lines[:-1]:
                    yield f"data: {json.dumps({'text': line})}\n\n"
                buffer = lines[-1]

            # Yield any remaining content in the buffer
            if buffer:
                yield f"data: {json.dumps({'text': buffer})}\n\n"
        except openai.NotFoundError:
            yield f"data: {json.dumps({'text': 'í† í°ì´ ë¶€ì¡±í•©ë‹ˆë‹¤'})}\n\n"
            
        except Exception as e:
            yield f"data: {json.dumps({'text': 'ê¸°íƒ€ ì—ëŸ¬ ë°œìƒ'})}\n\n"


    return generate
    #########################################################################################################
    # fewshot prompt
    # llm = ChatOpenAI(model_name = "gpt-4o", streaming=True, callbacks=[StreamingStdOutCallbackHandler()],
    #                 temperature = 0,
    #                 openai_api_key= openai_api_key)
    # prompt = load_prompt(os.path.join('/app/src/quiz/utils/prompt', 'quiz_generator.yaml'))
    # topic = document.split('\n')[0]
    # reference = '\n'.join(document.split('\n')[1:])
    # quiz_content_list = {'vocabulary_focused':'create quizzes based on words',
    #                 'sentence_example':'create quizzes based on sentences',
    #                 'cultural_information':'create quizzes based on culture',
    #                 'word_order':'create quizzes based on the order of words'}
    # quiz_content_prompt = ''
    # for i in quiz_content:
    #     quiz_content_prompt = quiz_content_prompt + '-'+ quiz_content_list[i] + '\n'
    # quiz_type_list={'multiple_choice':'create multiple choice quizzes',
    #        'true_or_false':'create true/false quizzes',
    #        'fill_in_the_blank':'create fill-in-the-blank quizzes'}
    
    # quiz_type_prompt = ''
    # for i in quiz_type:
    #     quiz_type_prompt = quiz_type_prompt + '-'+ quiz_type_list[i] + '\n'

    # fewshot_prompt = sample_fewshot(quiz_content,quiz_type,number)
    # input_data = {"topic": topic,"reference": reference,"quiz_content":quiz_content,"quiz_type":quiz_type,"fewshot":fewshot_prompt,"number":number}
    # rag_chain = (
    #     prompt
    #     | llm
    #     | StrOutputParser()
    # )

    # results = rag_chain.invoke(input_data)
    # return results
